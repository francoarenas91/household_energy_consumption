---
title: "prediction_models"
output: html_document
date: "2023-11-18"
---


0. clear environment, package load and set directory
```{r}
rm(list = ls())


##carga paquetes

PAQUETES <- c("dplyr","tidyverse","ggplot2","here","arrow","lubridate","readxl","randomForest","plm","caret")

for (el in PAQUETES){
  if (!require(el, character.only = TRUE)) {
    install.packages(el, repos = "https://cloud.r-project.org")
    require(el, character.only = TRUE)
  }
}

rm(PAQUETES, el)

path<-here()
setwd(path)

```


```{r}
house_static_data <- read_parquet("https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/static_house_info.parquet") %>% 
  select(bldg_id,in.county) %>% 
  rename(county_id=in.county)
temperature <-read_csv("~/GitHub/household_energy_consumption/data/temperature.csv") %>% 
  rename(time=date_time)
data <-read_csv("C:/Users/usuario/OneDrive/MADS/IST687/final_project/electricity_consumption.csv") %>%
  # sample_frac(.20) %>% 
  left_join(house_static_data,by="bldg_id") %>% 
  left_join(temperature,by=c("county_id","time")) %>% #join with encoded data
  group_by(county_id,time) %>% 
  summarise(
    total_electricity=sum(total_electricity),
    temperature = mean(temperature)
  ) %>% 
  mutate(total_electricity=log(total_electricity)) #log transformation so the betas are interpreted as percentage increase/decrease


```

Esentially, this is a panel data regression problem, so we need to isolate individual effects and time effects
```{r}
panel_data <- pdata.frame(data, index = c("county_id", "time"))

#run a fixed effects model
panel_model <- plm(total_electricity ~ temperature, 
                data = panel_data, 
                model = "within")
summary(panel_model)

```
only R squred of 0.13, so it is a bad fit


try alternative model extracting hour and date
```{r}
data %>% 
  mutate(day = factor(day(time))) %>% 
  mutate(day_of_week = factor(as.numeric(wday(time, label = TRUE)))) %>% #start in sunday
  filter(!is.na(temperature)) %>%  #drop the counties where I do not have the temperature
  mutate(hour=factor(hour(time))) %>% 
  select(-day) %>% #colinear with day of the week
  select(-time)-> data_times

```

```{r}
lm_model_dates <- lm(total_electricity~.,data=data_times)

summary(lm_model_dates)
```
good fit, 0.99

Lets do test train split and cross validation to compare with other models
```{r}
set.seed(123)  # for reproducibility
trainIndex <- createDataPartition(data_times$total_electricity, p = .8, 
                                  list = FALSE, 
                                  times = 1)

dataTrain <- data_times[ trainIndex,]
dataTest  <- data_times[-trainIndex,]

train_control <- trainControl(method = "cv", number = 10)

```

rerun the previous linear model
```{r}
# Train a linear regression model on the training set
lm_model <- train(total_electricity ~ ., data = dataTrain, method = "lm", trControl = train_control)

# Print the results
summary(lm_model)

# Make predictions on the test set
predictions <- predict(lm_model, newdata = dataTest)

# Calculate performance metrics on the test set
postResample(pred = predictions, obs = dataTest$total_electricity)

```
let's try adding a square term in temperature to account for non linearities
```{r}
data_squared <- data_times %>% 
  mutate(sqr_temperature=temperature^2)

trainIndex <- createDataPartition(data_squared$total_electricity, p = .8, 
                                  list = FALSE, 
                                  times = 1)

dataTrain <- data_squared[ trainIndex,]
dataTest  <- data_squared[-trainIndex,]

# Train a linear regression model on the training set
sq_lm_model <- train(total_electricity ~ ., data = dataTrain, method = "lm", trControl = train_control)

# Print the results
summary(sq_lm_model)

# Make predictions on the test set
predictions <- predict(sq_lm_model, newdata = dataTest)

# Calculate performance metrics on the test set
postResample(pred = predictions, obs = dataTest$total_electricity)

```
the square term is significant, nonetheless it does not significantly improve the model
We do not try a random forest, as it struggles with extrapolation, and that is the aim of our analysis.



Make the predictions for the 5 degrees increase in temperature
```{r}
# Increase temperature by 5 degrees in the dataset
data_pred <- data_times %>% 
  mutate(temperature=temperature+5) 

# Predict electricity consumption with the updated temperature
predictions <- predict(lm_model, newdata = data_pred)

# Convert log-scale predictions back to original scale
data_pred$total_electricity = exp(predictions)
```

